{
  "1": {
    "inputs": {
      "ckpt_name": "igame_SDXL_V1.4.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "4": {
    "inputs": {
      "text": "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name,\n\n\n",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "strength": 0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "69",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "control_net": [
        "7",
        0
      ],
      "image": [
        "91",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "7": {
    "inputs": {
      "control_net_name": "controlnet-sd-xl-1.0-softedge-dexined.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model 🛂🅐🅒🅝"
    }
  },
  "8": {
    "inputs": {
      "strength": 0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "5",
        0
      ],
      "negative": [
        "5",
        1
      ],
      "control_net": [
        "9",
        0
      ],
      "image": [
        "51",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "9": {
    "inputs": {
      "control_net_name": "t2iadapter_color_sd14v1.pth"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model 🛂🅐🅒🅝"
    }
  },
  "10": {
    "inputs": {
      "strength": 0,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "5",
        0
      ],
      "negative": [
        "5",
        1
      ],
      "control_net": [
        "11",
        0
      ],
      "image": [
        "52",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "11": {
    "inputs": {
      "control_net_name": "OpenPoseXL2.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model 🛂🅐🅒🅝"
    }
  },
  "12": {
    "inputs": {
      "strength": 0,
      "start_percent": 0,
      "end_percent": 0.5,
      "positive": [
        "10",
        0
      ],
      "negative": [
        "10",
        1
      ],
      "control_net": [
        "13",
        0
      ],
      "image": [
        "53",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "13": {
    "inputs": {
      "control_net_name": "TTPLANET_Controlnet_Tile_realistic_v1_fp32.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model 🛂🅐🅒🅝"
    }
  },
  "14": {
    "inputs": {
      "seed": 1003897265072418,
      "steps": 28,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "108",
        0
      ],
      "positive": [
        "74",
        0
      ],
      "negative": [
        "74",
        1
      ],
      "latent_image": [
        "71",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "16": {
    "inputs": {
      "samples": [
        "14",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "20": {
    "inputs": {
      "image": "static.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "21": {
    "inputs": {
      "image": "static.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "22": {
    "inputs": {
      "image": "static.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "23": {
    "inputs": {
      "image": "static.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "26": {
    "inputs": {
      "stop_at_clip_layer": -1,
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "44": {
    "inputs": {
      "lora_name": "Fay.safetensors",
      "strength_model": 0,
      "strength_clip": 0,
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "51": {
    "inputs": {
      "resolution": 1024,
      "image": [
        "21",
        0
      ]
    },
    "class_type": "ColorPreprocessor",
    "_meta": {
      "title": "Color Pallete"
    }
  },
  "52": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": [
        "104",
        0
      ],
      "image": [
        "22",
        0
      ]
    },
    "class_type": "OpenposePreprocessor",
    "_meta": {
      "title": "OpenPose Pose"
    }
  },
  "53": {
    "inputs": {
      "pyrUp_iters": 3,
      "resolution": [
        "106",
        0
      ],
      "image": [
        "23",
        0
      ]
    },
    "class_type": "TilePreprocessor",
    "_meta": {
      "title": "Tile"
    }
  },
  "69": {
    "inputs": {
      "text": "(best quality, highest quality),TRQ style,A girl holds her chin in her hands, smiling, with soft eyes, wearing green translucent clothes",
      "clip": [
        "44",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "71": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "72": {
    "inputs": {
      "image": "static.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "74": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "12",
        0
      ],
      "negative": [
        "12",
        1
      ],
      "control_net": [
        "75",
        0
      ],
      "image": [
        "96",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "75": {
    "inputs": {
      "control_net_name": "control-lora-canny-rank256.safetensors"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model 🛂🅐🅒🅝"
    }
  },
  "81": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "16",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "91": {
    "inputs": {
      "safe": "enable",
      "resolution": [
        "101",
        0
      ],
      "image": [
        "20",
        0
      ]
    },
    "class_type": "PiDiNetPreprocessor",
    "_meta": {
      "title": "PiDiNet Soft-Edge Lines"
    }
  },
  "96": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "resolution": [
        "98",
        0
      ],
      "image": [
        "72",
        0
      ]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {
      "title": "Canny Edge"
    }
  },
  "98": {
    "inputs": {
      "image_gen_width": [
        "99",
        0
      ],
      "image_gen_height": [
        "99",
        1
      ],
      "resize_mode": "Just Resize",
      "original_image": [
        "72",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "99": {
    "inputs": {
      "image": [
        "72",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "🔧 Get Image Size"
    }
  },
  "101": {
    "inputs": {
      "image_gen_width": [
        "102",
        0
      ],
      "image_gen_height": [
        "102",
        1
      ],
      "resize_mode": "Just Resize",
      "original_image": [
        "20",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "102": {
    "inputs": {
      "image": [
        "20",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "🔧 Get Image Size"
    }
  },
  "104": {
    "inputs": {
      "image_gen_width": [
        "105",
        0
      ],
      "image_gen_height": [
        "105",
        1
      ],
      "resize_mode": "Just Resize",
      "original_image": [
        "22",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "105": {
    "inputs": {
      "image": [
        "22",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "🔧 Get Image Size"
    }
  },
  "106": {
    "inputs": {
      "image_gen_width": [
        "107",
        0
      ],
      "image_gen_height": [
        "107",
        1
      ],
      "resize_mode": "Just Resize",
      "original_image": [
        "23",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "107": {
    "inputs": {
      "image": [
        "23",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "🔧 Get Image Size"
    }
  },
  "108": {
    "inputs": {
      "switch": "Off",
      "lora_name": "add_detail_igame_SDXL.safetensors",
      "strength_model": 0.65,
      "strength_clip": 1,
      "model": [
        "44",
        0
      ],
      "clip": [
        "44",
        1
      ]
    },
    "class_type": "CR Load LoRA",
    "_meta": {
      "title": "💊 CR Load LoRA"
    }
  }
}