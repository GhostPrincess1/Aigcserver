{
  "60": {
    "inputs": {
      "ckpt_name": "ROK_V1.2.ckpt"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "63": {
    "inputs": {
      "text": "embedding:badoutV2.pt,",
      "clip": [
        "80",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "64": {
    "inputs": {
      "text": [
        "97",
        0
      ],
      "clip": [
        "80",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "65": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 282937027233140,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "start_at_step": 0,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "95",
        0
      ],
      "positive": [
        "109",
        0
      ],
      "negative": [
        "109",
        1
      ],
      "latent_image": [
        "68",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "68": {
    "inputs": {
      "width": [
        "73",
        2
      ],
      "height": [
        "75",
        2
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "69": {
    "inputs": {
      "samples": [
        "65",
        0
      ],
      "vae": [
        "60",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "73": {
    "inputs": {
      "number_type": "integer",
      "number": 512
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "75": {
    "inputs": {
      "number_type": "integer",
      "number": 850
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "80": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "95",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "81": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "64",
        0
      ],
      "negative": [
        "63",
        0
      ],
      "control_net": [
        "93",
        0
      ],
      "image": [
        "85",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "85": {
    "inputs": {
      "preprocessor": "DWPreprocessor",
      "resolution": [
        "92",
        0
      ],
      "image": [
        "149",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "87": {
    "inputs": {
      "image": "‰∏ãËΩΩ (1) (1).png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "92": {
    "inputs": {
      "image_gen_width": [
        "151",
        0
      ],
      "image_gen_height": [
        "151",
        1
      ],
      "resize_mode": "Crop and Resize",
      "original_image": [
        "149",
        0
      ]
    },
    "class_type": "PixelPerfectResolution",
    "_meta": {
      "title": "Pixel Perfect Resolution"
    }
  },
  "93": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_openpose_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "95": {
    "inputs": {
      "lora_name": "ROK_Boudica.safetensors",
      "strength_model": 0.75,
      "strength_clip": 0.75,
      "model": [
        "60",
        0
      ],
      "clip": [
        "60",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "97": {
    "inputs": {
      "python_expression": "a + b + c",
      "print_to_console": "False",
      "a": [
        "156",
        0
      ],
      "b": [
        "157",
        0
      ],
      "c": [
        "155",
        0
      ]
    },
    "class_type": "Evaluate Strings",
    "_meta": {
      "title": "Evaluate Strings"
    }
  },
  "98": {
    "inputs": {
      "upscale_model": [
        "99",
        0
      ],
      "image": [
        "69",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "99": {
    "inputs": {
      "model_name": "RealESRGAN_x2.pth"
    },
    "class_type": "Upscale Model Loader",
    "_meta": {
      "title": "Upscale Model Loader"
    }
  },
  "102": {
    "inputs": {
      "pixels": [
        "98",
        0
      ],
      "vae": [
        "103",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "103": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "104": {
    "inputs": {
      "samples": [
        "106",
        0
      ],
      "vae": [
        "103",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "105": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "104",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "106": {
    "inputs": {
      "seed": 160557466192263,
      "steps": 20,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.45,
      "model": [
        "95",
        0
      ],
      "positive": [
        "113",
        0
      ],
      "negative": [
        "113",
        1
      ],
      "latent_image": [
        "102",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "109": {
    "inputs": {
      "strength": 0.35000000000000003,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "81",
        0
      ],
      "negative": [
        "81",
        1
      ],
      "control_net": [
        "111",
        0
      ],
      "image": [
        "110",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "110": {
    "inputs": {
      "preprocessor": "MiDaS-DepthMapPreprocessor",
      "resolution": [
        "92",
        0
      ],
      "image": [
        "149",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "111": {
    "inputs": {
      "control_net_name": "control_v11f1p_sd15_depth.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "113": {
    "inputs": {
      "strength": 0.35000000000000003,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "147",
        0
      ],
      "negative": [
        "63",
        0
      ],
      "control_net": [
        "115",
        0
      ],
      "image": [
        "114",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "114": {
    "inputs": {
      "preprocessor": "PiDiNetPreprocessor",
      "resolution": [
        "92",
        0
      ],
      "image": [
        "98",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "115": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_softedge.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "146": {
    "inputs": {
      "model": "wd-v1-4-moat-tagger-v2",
      "threshold": 0.65,
      "character_threshold": 0.85,
      "replace_underscore": "",
      "trailing_comma": false,
      "exclude_tags": "",
      "image": [
        "98",
        0
      ]
    },
    "class_type": "WD14Tagger|pysssss",
    "_meta": {
      "title": "WD14 Tagger üêç"
    }
  },
  "147": {
    "inputs": {
      "text": [
        "146",
        0
      ],
      "clip": [
        "80",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "149": {
    "inputs": {
      "transparency": false,
      "model": "u2netp",
      "post_processing": false,
      "only_mask": false,
      "alpha_matting": false,
      "alpha_matting_foreground_threshold": 240,
      "alpha_matting_background_threshold": 10,
      "alpha_matting_erode_size": 10,
      "background_color": "none",
      "images": [
        "87",
        0
      ]
    },
    "class_type": "Image Rembg (Remove Background)",
    "_meta": {
      "title": "Image Rembg (Remove Background)"
    }
  },
  "151": {
    "inputs": {
      "image": [
        "149",
        0
      ]
    },
    "class_type": "ImageSizeAndBatchSize",
    "_meta": {
      "title": "Get Image Size + Batch Size"
    }
  },
  "155": {
    "inputs": {
      "prompt": ""
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "156": {
    "inputs": {
      "prompt": "(masterpiece:1.2), (best quality, highest quality),"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "157": {
    "inputs": {
      "prompt": "Dolly,1girl,  hair ribbon, ponytail, braid,"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  }
}